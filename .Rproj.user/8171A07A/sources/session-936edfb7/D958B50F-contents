
# Libraries ####
library(tidyverse)
library(splitstackshape) 
library(tm)
library(tidymodels)
library(tidytext)
library(textrecipes)
library(ggwordcloud)
library(textdata)
library(saotd)
library(syuzhet)
library(stringr)
library(lubridate)
library(DT)

# List of dashboard colors to use




# Data ####
Data <- read.csv("Data/Tweets2.csv")
RawCopy <- Data

# Data wrangling ####

# Split the column user_location to Location
Data <- cSplit(Data, 'user_location', sep=",", type.convert=FALSE)

# Extract frequency of hashtags
Hashtags <- str_remove_all(Data$hashtags, "[^ \\w+]") |> 
  str_split(" ") |> unlist() |> table()

# convert it to a dataframe
Hashtags <- as.data.frame(Hashtags)

# Replace empty strings with NA
Hashtags[Hashtags == ''] <- NA

# Remove all NA's and rename the columns
Hashtags <- Hashtags %>%
  na.omit() %>%
  rename(Hashtag = Var1, 
         Count  = Freq)%>%
  filter(Count>2)



# Create a wordcloud
wordcloudHashtags <- ggplot(data = Hashtags, 
       aes(label = Hashtag, size = Count, col = as.character(Count))) + 
  geom_text_wordcloud(rm_outside = TRUE, max_steps = 1,
                      grid_size = 1, eccentricity = .9)+
  scale_size_area(max_size = 13)+
  labs(title = "World cloud of common hashtags")+ 
  theme_minimal()
  # scale_color_brewer(palette = "Paired", direction = -1)+
wordcloudHashtags

# Convert Date column from character to Date
# Its in the format of date, month, year (dmy). 
# Data$date <- dmy(Data$date)
Data$date <- as.Date(Data$date, "%d/%m/%Y")

Countoftweets <- Data %>%
  select(date) %>%
  group_by(date) %>%
  summarise(count = n())
Countoftweets

# Line Chart of count COVID19-Tweets
time.series.tweets <- ggplot(Countoftweets, aes(x=date, y=count)) +
  # geom_line(color="#F52C65", linewidth=0.5) + 
  geom_line(color="#F05F1D", linewidth=0.5) + 
  theme_minimal() +
  xlab("") +
  labs(
    title = "Temporal count of COVID-19 Vaccine tweets", 
    caption = "Source: Twitter"
  )
  
time.series.tweets


# Remove emoticons, punctuation marks, and stopwords from the dataframe
TidyTweets <- saotd::tweet_tidy(DataFrame = Data)

# Create un-igrams, bi-grams and tri-grams
unigram.df <- unigram(DataFrame = TidyTweets)
bigram.df <- bigram(DataFrame = TidyTweets)
trigram.df <- trigram(DataFrame = TidyTweets)


# Create a unigram wordcloud
unigram.df <- unigram.df %>%
  filter(n>50)
unigram.wordcloud <- ggplot(data = unigram.df, 
                            aes(label = word, size = n, col = as.character(n))) + 
  geom_text_wordcloud(rm_outside = TRUE, max_steps = 1,
                      grid_size = 1, eccentricity = .9)+
  scale_size_area(max_size = 13)+
  labs(title = "World cloud of unigrams")+
  # scale_color_brewer(palette = "Paired", direction = -1)+
  theme_minimal()
unigram.wordcloud


# Network diagram of bigrams
bigram.network <- bigram_network(bigram.df, edge_color = "#00B39A" , node_color = "#F05F1D", set_seed = 1234, layout = "fr", number = 70)
bigram.network
#F52C65

  
# Derive sentiment classifiers
location.senti.score <- data_frame(id=TidyTweets$user_location_1, text = TidyTweets$text) %>% 
  unnest_tokens(word, text) %>%
  anti_join(stop_words) %>%
  inner_join(get_sentiments("nrc")) %>%
  mutate(score = ifelse(sentiment=='positive',1,
                        ifelse(sentiment=='joy',1,
                               ifelse(sentiment=='anticipation',1,
                                      ifelse(sentiment=='trust',1,
                                             ifelse(sentiment=='surprise',1,-1)))))) %>%
  group_by(id) %>%
  summarise(total_score = sum(score)) %>%
  mutate(sentiment = ifelse(total_score>0,'positive',ifelse(total_score<0,'negative','neutral')))


# Columnplot of location-based tweets based on the sentimentscore
loc.sentiscore <- ggplot(location.senti.score, aes(reorder(id, -total_score), total_score, fill=sentiment)) + 
  geom_col() +
  theme_minimal() +
  labs(x ="", y="score", title = "Sentiment scores per location", caption = "Source: Twitter") +
  theme(legend.position = "bottom",
        legend.title = element_blank(), 
        axis.text.x = element_text(angle = 30, vjust = 0.5, hjust = 1))+
  geom_text(aes(label = total_score), vjust = -0.5, size = 3)
loc.sentiscore


# Overall sentiscore
TidyTweets <- tibble::rowid_to_column(TidyTweets, "id")
senti.score <- data_frame(id=TidyTweets$id, text = TidyTweets$text) %>% 
  unnest_tokens(word, text) %>%
  anti_join(stop_words) %>%
  inner_join(get_sentiments("nrc")) %>%
  mutate(score = ifelse(sentiment=='positive',1,ifelse(sentiment=='joy',1,ifelse(sentiment=='anticipation',1,ifelse(sentiment=='trust',1,ifelse(sentiment=='surprise',1,-1)))))) %>%
  group_by(id) %>%
  summarise(total_score = sum(score)) %>%
  mutate(sentiment = ifelse(total_score>0,'positive',ifelse(total_score<0,'negative','neutral')))

# get the dataframe which contains tweet message, id and it's sentiment
senti.score <- TidyTweets %>% inner_join(senti.score, by='id') %>% select('id', 'text','sentiment')

# Recode the response variable to integers
Tweets <- senti.score %>%
  mutate(score = recode(sentiment, 'negative'=-1, 'neutral'=0, 'positive'=1))

